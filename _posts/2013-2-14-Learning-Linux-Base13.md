---
layout: post
title: 《鸟哥的Linux私房菜:基础篇》学习笔记——13.磁盘配额(Quota)与高级文件系统管理
time: 2013-2-14
category: LinuxBase
published: false
---


#磁盘配额(Quota)的应用与实践#

##什么是Quota##

Quota的一般用途:
- 针对WWW server,每个人的网页空间的容量限制
- 针对mail server,每个人的邮件空间限制
- 针对file server,每个人最大的可用网络硬盘空间
- 限制某一用户组所能使用的最大磁盘配额
- 以link的方式使邮件可以作为限制的配额(更改`/var/spool/mail`这个路径)

Quota的限制:
- 仅能针对整文件系统
- 内核必须支持quota
- 只对一般身份用户有效

Quota的规范设置选项
Quota针对整个文件系统的限制项目主要分为以下几个部分:

**容量限制或文件数量限制(block或inode)**
- 限制inode用量:管理用户可以新建的"文件数量"
- 限制block用量:管理用户磁盘容量的限制，较常见的为这种方式

**soft/hard**
- hard:表示用户决不超过这个限制值，若超过这个限制值系统会锁住该用户的磁盘使用权
- soft:表示用户低于soft值时，可以正常使用磁盘，但若超过soft且低于hard限制值时，每次用户登录系统时，系统会主动发出磁盘即将爆满的警告信息，且会给予一个宽限时间(gracetime)。不过，若用户在宽限时间倒数期间就将容量再次将低于soft限值之下，则宽限时间会停止

**会倒计时的宽限时间(gracetime)**
默认的宽限时间时7天，如果7天内都不进行任何磁盘管理，那么soft限制值会即刻取代hard限制值来作为quota的限制，此时你的磁盘使用权就会锁住而无法新增文件

##实践Quota流程1:文件系统支持##

要想使用Quota，就必须要在需要使用Quota的文件系统中启用Quota功能,启用命令:

{% highlight bash %}
mount -o remount,usrquota,grpquota /home
mount | grep home					#查看结果
{% endhighlight %}

使用如上的命令，当该文件系统重新挂载时，就会失去Quota功能，所以，如果想要长期使用Quota来限制一个文件系统，就必须要确定`/etc/mtab`已经加入usrquota、grpquota的支持到你所想要设置的文件系统中

{% highlight bash %}
vim /etc/fstab
LABEL=/home			/home 		ext4		defaults,usrquota,grpquota 1 2
{% endhighlight %}

##实践Quota流程2:新建Quta配置文件##

其实Quota是通过分析整个文件系统中每个用户(组)拥有的文件总数与总容量，再将这些数据记录在该文件系统的最顶层目录，然后在该配置文件中再使用每个账号(或用户组)的限制值去规定磁盘使用量的

**`quotacheck`:扫描文件系统并新建Quota的配置文件**
常用的命令参数只要记得`-avug`就行了，执行该命令后，会在文件系统的顶层目录新建两个文件:aquota.group,aquota.user。这两个文件是Quota自己的数据文件，并不是纯文本文件，且该文件一直变动，因此要新建这个两个文件，记得要使用`quotacheck`命令，不要手动编辑

##实践Quota流程3:Quota启动、关闭与限制值设置##

制作好Quota配置文件之后，接下来就是要启动quota了。启动的方式很简单，使用`quotaon`,至于关闭就用`quotaoff`即可。

`quotaon`:启动quota的服务
`quotaoff`:关闭quota的服务
`edquota`:编辑账号/用户组的限制与宽限时间

编辑Quota时，一共有七个字段，意义分别如下:
1. 文件系统(filesystem):说明该限制值时针对哪个文件系统
2. 磁盘容量(blocks):这个数值是quota自己算出来的，单位为KB，请不要修改它
3. soft:磁盘容量(block)的soft限制值，单位为KB
4. hard:block的hard限制值，单位KB
5. 文件数量(inodes):这是quota自己算出来的，单位为个数，请不要修改它
6. soft:inode的soft限制值
7. hard:inode的hard限制值

当soft/hard为0时，表示没有限制的意思

##实践Quota流程4:Quota限制值的报表##

quota的报表主要有两种模式，一种是针对每个个人或用户组的`quota`命令，一个是针对整个文件系统的`repquota`命令。

`quota`:单一用户的quota报表
`repquota`:针对文件系统的限额做报表

##实践Quota流程5:测试与管理##

`warnquota`:对超过限额者发出警告信。它可以根据`/etc/warnquota.conf`的设置，然后找出目前系统上面quota用量超过soft的账号，通过Email的功能将警告信件发送到用户的电子邮件信箱

`setquota`:直接于命令中设置quota限额

#软件磁盘阵列(Software RAID)#

##什么是RAID##

RAID(RedundantArrays of Inexpensive Disks),即容错廉价磁盘阵列。RAID可以通过一些技术(软件或硬件)将多个较小的磁盘整合成为一个较大的磁盘设备，而这个较大的磁盘功能可不止是存储而已，它还具有数据保护功能。
不同的等级有不同的功能:

**RAID-0(等量模式,stripe):性能最佳**
这种模式如果使用相同型号与容量的磁盘来组成时，效果最佳。这种模式的RAID将会将磁盘先切出等量的区块，然后当一个文件要写入RAID时，该文件会依据块的大小切割好，之后再依序放到各个磁盘里面去。由于每个磁盘会交错存放数据，因此当你的数据要写入RAID时，**数据会被等量放置在各个磁盘上面。**
越多块磁盘组成的RAID-0性能越好，因为每块负责的数据量就更低了。
但是性能好了，安全性就降低了。RAID-0只要有任何一块磁盘损坏，在RAID上面的所有数据都会丢失而无法读取。

**RADI-1(映像模式):完整备份**
这种模式也是需要相同的磁盘容量的，最好一模一样的磁盘。如果是不同容量的磁盘组成RAID-1时，那么总容量将以最小的那一块磁盘为主！这种模式主要是**让同一份数据完整保存在两块磁盘上**。
RAID-1最好的优点大概在于数据的备份，不过由于磁盘容量有一半用在备份，因此总容量会是全部磁盘容量的一半而已

**RAID0+1,RAID1+0**

RAID0+1就是先将两块磁盘组成RAID0，并且这样的设置共有两组；然后将这两组RAID0再组成一组RAID1。RAID1+0就是反过来，先组成RAID1，再组成RAID0

**RAID5:性能与数据备份的均衡考虑**

RAID-5至少需要三块以上的磁盘才能够组成这种类型的磁盘整列。这种磁盘阵列的数据写入有点类似RAID-0，不过每个循环的写入过程中，在每块磁盘还加入一个同位检查数据(Parity),这个数据会记录其他磁盘的备份数据，用于当磁盘损坏时的救援。
由于有同位检查码，因此RAID5的总容量会是整体磁盘数量减一块。而且当损坏的磁盘数量大于等于两块时，这整组RAID5的数据就损毁了。因为RAID5默认仅能够支持一块磁盘的损毁情况。

**Spare Disk:预备磁盘功能**
当磁盘阵列的磁盘损毁时，就得要将毁掉的磁盘拔出，然后换一块新的磁盘。换成新的磁盘并且顺利启动磁盘阵列后，磁盘阵列就会开始主动重建(rebuild)原本坏掉的那块磁盘数据到新的磁盘上，然后你的磁盘阵列上面的数据就能恢复了。
为了让系统可以实时地在坏掉硬盘时主动重建，因为就需要预备磁盘(spare disk)的辅助。所谓的sapre disk就是一块或多块没有包含在原本磁盘阵列等级中的磁盘，这块磁盘平时并不会被磁盘阵列所使用，当磁盘阵列有任何磁盘损毁时，则这块Spare disk会被主动拉进磁盘阵列中，并将坏掉的那块硬盘移除磁盘阵列，然后立即重建数据系统。

##software,hardware RAID##
所谓的硬件磁盘阵列(hardware RAID)是通过磁盘阵列卡来完成数组的目的。磁盘阵列卡上面有一个专门的芯片在处理RAID的任务，因此在性能方面会比较好，在很多任务时(例如RAID5的同为检查码)磁盘阵列并不会重复消耗原本系统的I/O总线，理论上性能会较佳。
由于磁盘阵列有很多优秀的功能，然而硬件磁盘阵列卡却很贵，因此就发展出利用软件来仿真磁盘阵列的功能，这就是所谓的软件磁盘阵列(software RAID).软件磁盘阵列主要是通过软件来仿真数组的任务，因此会损耗较多的系统资源，比如说CPU的运算与I/O总线资源等。

#逻辑卷管理器(Logical Volume Manager)#

LVM的重点在于可以弹性调整文件系统的容量！LVM可以整合多个物理分区在一起，让这些分区看起来就像是一个磁盘一样，而且，还可以在将来增加其他的物理分区或将其从这个LVM管理的磁盘当中删除。

##上面是LVM:PV,PE,VG,LV的意义##

LVM:Logical Volume Manager
LVM的做法是将几个物理的分区(或磁盘)通过软件组合成为一块看起来是独立的大磁盘(VG),然后将这块大磁盘再经过切分成为可使用分区(LV)，最终能够挂载使用了。

**PhysicalVolume,PV,物理卷**
我们实际的分区需要调整物理系统标示符(system ID)成为8e(LVM的标示符)，然后再经过pvcreate的命令将它转成LVM最底层的物理卷(PV)，之后才能够将这些PV加以利用，调整system ID的方法就是通过fdisk

**VolumeGroup,VG,卷用户组**
所谓的LVM大磁盘就是将许多PV整合成这个VG，所以VG就是LVM组合起来的大磁盘。那么这个大磁盘最大可以达到多少容量呢？这与下面要说明的PE有关，因为每个VG最多仅能包含65534个PE而已。如果使用LVM默认的参数，则一个VG最大可达256G的容量

**PhysicalExtend,PE,物理扩展块**
LVM默认使用4MB的PE块，而LVM的VG最多仅能包含65534个PE，因此默认的LVMVG会有4M*65534/(1024M/G)=256G。这个PE是整个LVM最小的存储块，也就是说，其实我们的文件数据都是由写入PE来处理的。简单的说，这个PE就有点像文件系统里面的block的大小。

**LogicalVolmue,LV,逻辑卷**
最终的VG还会被切分成LV，这个LV就是最后可以被格式化使用的类似分区。LV是不可以随意指定大小的，因为PE是整个LVM的最小存储单位，那么LV的大小就与在此LV内的PE总数有关。
LVM可以弹性更改文件系统的容量，其实它就是通过交换PE来进行数据交换，将原本LV内的PE移转到其他设备中以降低LV容量，或将其它设备的PE加到此LV中以加大容量。

在使用LVM时，依据写入机制的不同，而有两种方式:
- 线性模式(liner):一个分区接一个分区的写入
- 交错模式(triped):将一条数据拆成两部分，分别写入到两个分区中

基本上，LVM最主要的用处是在实现一个可以弹性调整容量的文件系统上，而不是在新建一个性能为主的磁盘上。

